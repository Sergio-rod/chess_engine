{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f738d7b1-089b-4b95-8723-97fbba9e189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "import chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d0072c-c552-4f19-9aea-cb5a9f058494",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquets = glob.glob('../data/processed/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f298a1-4c7a-433d-90eb-26e2296cfd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_million_games = pd.concat([pd.read_parquet(parquet) for parquet in parquets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9a2093-8711-4726-8647-995475b26ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_uci_move_vocabulary() -> tuple[dict,dict]:\n",
    "\n",
    "    \"\"\"\n",
    "    Generates a set of all the posible movements in a chess board of 64 squares, \n",
    "    create two dictionaries which will represent the board move in uci format and their respective idx value and viceversa\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        uci_to_idx : dict\n",
    "                     All the possible uci moves in a chess board, uci format as keys and idx as values\n",
    "        idx_to_uci : dict \n",
    "                     All the possible uci moves in a chess board, uci format as keys and idx as values\n",
    "    \n",
    "    \"\"\"\n",
    "    move_set = set()\n",
    "    \n",
    "    for from_sq in chess.SQUARES:\n",
    "        for to_sq in chess.SQUARES:\n",
    "            if from_sq == to_sq:\n",
    "                continue\n",
    "\n",
    "            move = chess.Move(from_sq, to_sq)\n",
    "            move_set.add(move.uci())\n",
    "            \n",
    "            from_rank = chess.square_rank(from_sq) # Get the row in which the piece is coming from\n",
    "            to_rank = chess.square_rank(to_sq) # Get the row in which will be moved the piece\n",
    "            # if to_rank in [0, 7] and from_rank in [1,6]:  # posibles promociones\n",
    "            if (from_rank == 1 and to_rank == 0) or (from_rank == 6 and to_rank ==7):\n",
    "                \n",
    "                for promo in [chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT]:\n",
    "                    move_set.add(chess.Move(from_sq, to_sq, promotion=promo).uci())\n",
    "                    \n",
    "    move_list = sorted(move_set)\n",
    "    uci_to_idx = {uci: idx for idx, uci in enumerate(move_list)}\n",
    "    idx_to_uci = {idx: uci for uci, idx in uci_to_idx.items()}\n",
    "    return uci_to_idx, idx_to_uci\n",
    "\n",
    "def fen_to_tensor(fen:str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts a FEN position into a torch tensor of shape (12,8,8),\n",
    "    12 matrix of 8x8 positions, in which each type of piece eaither PNBRQK or pnbrqk,\n",
    "    will ocupate a place in the matrix, each matrix for each set of piece representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fen : str\n",
    "          The notation FEN to convert into numerical values\n",
    "    Returns\n",
    "    -------\n",
    "    board_tensor : torch.Tensor\n",
    "                   The representation of FEN notation in 12 matrix of 8x8\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    board = chess.Board(fen)\n",
    "    \n",
    "    piece_to_index = {piece:idx for idx,piece in enumerate('PNBRQKpnbrqk')} # represents the piece and index of each value of the str\n",
    "\n",
    "    #TODO: add extra ccanals to indicate if there is castling available 4 canals, passant square, halfmove clock\n",
    "    \n",
    "    board_tensor = torch.zeros((12,8,8),dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            idx = piece_to_index[piece.symbol()]\n",
    "            row = 7 - (square // 8)\n",
    "            col = square %8\n",
    "            board_tensor[idx,row,col] = 1.0\n",
    "    return board_tensor\n",
    "\n",
    "\n",
    "def get_legal_moves_vocab(fen:str) -> tuple[dict[str,int],dict[int,str]]:\n",
    "    \"\"\"\n",
    "    Generates a set of legal posible moves for a given position \n",
    "\n",
    "    IMPORTANT ---> All the dict generated are LOCAL and could not match with the global dict --> generate_full_uci_move_vocabulary()\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        fen: FEN notation of the current position\n",
    "    Returns\n",
    "    -------\n",
    "        uci_to_idx: Dict {uci_move : idx}\n",
    "        idc_to_uci: Dict {idx : uci_move}\n",
    "    \"\"\"\n",
    "\n",
    "    board = chess.Board(fen)\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    \n",
    "    legal_moves_sorted = sorted(legal_moves, key=lambda m: m.uci())\n",
    "\n",
    "    uci_to_idx = {move.uci():  idx for idx, move in enumerate(legal_moves_sorted)}\n",
    "    idx_to_uci = {idx: move.uci() for idx,move in enumerate(legal_moves_sorted)}\n",
    "    return uci_to_idx, idx_to_uci\n",
    "\n",
    " ## POSIBLEMENTE DESCARTADO, MEJORA ALTERNATIVA CON FUNCION  --> get_legal_moves_vocab enfoque \"SPARSE\"\n",
    "# def get_legal_mask(board: chess.Board, uci_to_index: dict) -> torch.Tensor:\n",
    "#     mask = torch.zeros(len(uci_to_index), dtype=torch.float32)\n",
    "#     for move in board.legal_moves:\n",
    "#         uci = move.uci()\n",
    "#         if uci in uci_to_index:\n",
    "#             mask[uci_to_index[uci]] = 1.0\n",
    "#     return mask  # Shape: (n_moves,)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    move_list = sorted(move_set)\n",
    "    uci_to_index = {uci: idx for idx, uci in enumerate(move_list)}\n",
    "    index_to_uci = {idx: uci for uci, idx in uci_to_index.items()}\n",
    "    return uci_to_index, index_to_uci\n",
    "# Globales cargados una vez al inicio\n",
    "\n",
    "def move_to_index(uci_move: str) -> int:\n",
    "    return uci_to_index.get(uci_move, -1)  # -1 si no está\n",
    "\n",
    "def index_to_move(idx: int) -> str:\n",
    "    return index_to_uci.get(idx, \"0000\")  # dummy por si acaso\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc91e526-b54d-4b09-8859-55fc4351852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessSequenceDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,df,uci_to_idx):\n",
    "\n",
    "        \n",
    "        self.games = []\n",
    "        self.uci_to_idx = uci_to_idx\n",
    "        grouped = df.groupby('game_id')\n",
    "\n",
    "        for game_id, group in grouped:\n",
    "            group_sorted = group.sort_values(by='ply',ascending=True)#group.sort_values(by='pyl',ascending=True)\n",
    "            sequence = []\n",
    "\n",
    "            for _,row in group_sorted.iterrows():\n",
    "                fen = row['fen']\n",
    "                uci = row['move_uci']\n",
    "\n",
    "                move_idx = uci_to_idx.get(uci,-1)\n",
    "                if move_idx ==-1:\n",
    "                    continue\n",
    "                try:\n",
    "                    fen_tensor = fen_to_tensor(fen)\n",
    "                except Exception as e:\n",
    "                    print(f'Error in FEN {fen} --->{e}')\n",
    "                    continue\n",
    "                sequence.append((fen_tensor,move_idx))\n",
    "            if len(sequence)>0:\n",
    "                self.games.append(sequence)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.games)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.games[idx]\n",
    "        \n",
    "def identity_collate(batch):\n",
    "    return batch[0]  # simplemente devuelve la secuencia tal cual\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3fa30ce-8b91-41bc-aa62-c0cd9b7f6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessLSTMPolicyNet(torch.nn.Module):\n",
    "    def __init__(self,input_channels=12,lstm_hidden_size=512,lstm_layers=1,output_dim=4544):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(input_channels,64,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.flattened_size = 128*8*8\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size= self.flattened_size,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc = torch.nn.Linear(lstm_hidden_size,output_dim)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "            B, T, C, H, W = x.shape\n",
    "            x = x.view(B * T, C, H, W)           # (B*T, C, 8, 8)\n",
    "            x = self.conv(x)                     # (B*T, 128, 8, 8)\n",
    "            x = x.view(B, T, -1)                 # (B, T, 8192)\n",
    "\n",
    "            lstm_out, _ = self.lstm(x)           # (B, T, hidden)\n",
    "            logits = self.fc(lstm_out)           # (B, T, output_dim)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b1f299c-fc9d-4a91-98c1-a26b4059d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_moves = 0\n",
    "\n",
    "        for sequence in dataloader:\n",
    "            # batch: list of 1 element (sequence of (fen_tensor, move_idx))\n",
    "            if not all(isinstance(x,tuple) and isinstance(x[0],torch.Tensor) for x in sequence):\n",
    "                print('Invalid sequence detected and omitted...')\n",
    "                continue\n",
    "            try: \n",
    "                \n",
    "                inputs = torch.stack([x[0] for x in sequence])  # (T, C, 8, 8)\n",
    "                targets = torch.tensor([x[1] for x in sequence],dtype=torch.long)  # (T,)\n",
    "\n",
    "            # Reshape to (B, T, C, 8, 8)\n",
    "                inputs = inputs.unsqueeze(0).to(device)\n",
    "                targets = targets.unsqueeze(0).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)  # (B, T, output_dim)\n",
    "\n",
    "            # Aplanar para CrossEntropy\n",
    "                logits = outputs.view(-1, outputs.size(-1))     # (T, output_dim)\n",
    "                target_flat = targets.view(-1)                  # (T,)\n",
    "\n",
    "                loss = criterion(logits, target_flat)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                total_loss += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                total_correct += (preds == target_flat).sum().item()\n",
    "                total_moves += target_flat.size(0)\n",
    "            except Exception as e:\n",
    "                print(f'Something went wrong error {e}, skipping sequence')\n",
    "                continue\n",
    "\n",
    "        acc = total_correct / total_moves\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}, Accuracy = {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ebefe2-8a8c-41d4-8b3c-14201db2885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(parquets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b60e648-d560-4f6c-8863-b288817a80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = list(df['game_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d9860b-c97a-4061-895b-41e5392b8cd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game_samples_id = np.random.choice(game_ids,size=1,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7974f452-4cde-4dcf-afa2-26b6311dd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_samples_df = df.loc[df['game_id'].isin(game_samples_id)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0b53e15-9367-4764-82a4-23bafa8e2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_to_idx,idx_to_uci = generate_full_uci_move_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f318793e-2422-4f22-ad36-6355520b8ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.utils' from '/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/__init__.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86d213a1-2627-489b-8b9f-bb1463660857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset y dataloader (batch_size = 1 por ahora)\n",
    "dataset = ChessSequenceDataset(game_samples_df, uci_to_idx)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True,collate_fn=identity_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0224099-e192-4123-8857-dea185099d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ChessLSTMPolicyNet(\n",
    "    input_channels=12,\n",
    "    lstm_hidden_size=512,\n",
    "    output_dim=len(uci_to_idx)\n",
    ").to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d99e044-9c37-4e44-80fd-9203e38e4550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 8.4218, Accuracy = 0.0000\n",
      "Epoch 2: Loss = 8.2037, Accuracy = 0.0526\n",
      "Epoch 3: Loss = 7.5742, Accuracy = 0.0526\n",
      "Epoch 4: Loss = 6.6634, Accuracy = 0.0351\n",
      "Epoch 5: Loss = 5.7310, Accuracy = 0.0351\n"
     ]
    }
   ],
   "source": [
    "train_lstm(model, loader, criterion, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1df22f75-c3a0-470f-ab3c-42f819b500fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "57\n",
      "<class 'tuple'>\n",
      "torch.Size([12, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    print(type(batch))           # <class 'list'>\n",
    "    print(len(batch))            # 57 ← número de jugadas en la partida\n",
    "    print(type(batch[0]))        # <class 'tuple'>\n",
    "    print(batch[0][0].shape)     # torch.Size([12, 8, 8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683beeb8-bda1-4bb1-8b38-1e4227663518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess_ai_env",
   "language": "python",
   "name": "chess_ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
