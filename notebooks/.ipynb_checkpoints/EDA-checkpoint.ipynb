{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f738d7b1-089b-4b95-8723-97fbba9e189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "import chess\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9a2093-8711-4726-8647-995475b26ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_uci_move_vocabulary() -> tuple[dict,dict]:\n",
    "\n",
    "    \"\"\"\n",
    "    Generates a set of all the posible movements in a chess board of 64 squares, \n",
    "    create two dictionaries which will represent the board move in uci format and their respective idx value and viceversa\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        uci_to_idx : dict\n",
    "                     All the possible uci moves in a chess board, uci format as keys and idx as values\n",
    "        idx_to_uci : dict \n",
    "                     All the possible uci moves in a chess board, uci format as keys and idx as values\n",
    "    \n",
    "    \"\"\"\n",
    "    move_set = set()\n",
    "    \n",
    "    for from_sq in chess.SQUARES:\n",
    "        for to_sq in chess.SQUARES:\n",
    "            if from_sq == to_sq:\n",
    "                continue\n",
    "\n",
    "            move = chess.Move(from_sq, to_sq)\n",
    "            move_set.add(move.uci())\n",
    "            \n",
    "            from_rank = chess.square_rank(from_sq) # Get the row in which the piece is coming from\n",
    "            to_rank = chess.square_rank(to_sq) # Get the row in which will be moved the piece\n",
    "            # if to_rank in [0, 7] and from_rank in [1,6]:  # posibles promociones\n",
    "            if (from_rank == 1 and to_rank == 0) or (from_rank == 6 and to_rank ==7):\n",
    "                \n",
    "                for promo in [chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT]:\n",
    "                    move_set.add(chess.Move(from_sq, to_sq, promotion=promo).uci())\n",
    "                    \n",
    "    move_list = sorted(move_set)\n",
    "    uci_to_idx = {uci: idx for idx, uci in enumerate(move_list)}\n",
    "    idx_to_uci = {idx: uci for uci, idx in uci_to_idx.items()}\n",
    "    return uci_to_idx, idx_to_uci\n",
    "\n",
    "def fen_to_tensor(fen:str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts a FEN position into a torch tensor of shape (12,8,8),\n",
    "    12 matrix of 8x8 positions, in which each type of piece eaither PNBRQK or pnbrqk,\n",
    "    will ocupate a place in the matrix, each matrix for each set of piece representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fen : str\n",
    "          The notation FEN to convert into numerical values\n",
    "    Returns\n",
    "    -------\n",
    "    board_tensor : torch.Tensor\n",
    "                   The representation of FEN notation in 12 matrix of 8x8\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    board = chess.Board(fen)\n",
    "    \n",
    "    piece_to_index = {piece:idx for idx,piece in enumerate('PNBRQKpnbrqk')} # represents the piece and index of each value of the str\n",
    "\n",
    "    #TODO: In version 2; add extra canals to indicate if there is castling available(4) canals,passant square(1), halfmove clock(1)\n",
    "    \n",
    "    board_tensor = torch.zeros((12,8,8),dtype=torch.float32)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            idx = piece_to_index[piece.symbol()]\n",
    "            row = 7 - (square // 8)\n",
    "            col = square %8\n",
    "            board_tensor[idx,row,col] = 1.0\n",
    "    return board_tensor\n",
    "\n",
    "\n",
    "def get_legal_moves_vocab(fen:str) -> tuple[dict[str,int],dict[int,str]]:\n",
    "    \"\"\"\n",
    "    Generates a set of legal posible moves for a given position \n",
    "\n",
    "    IMPORTANT ---> All the dict generated are LOCAL and could not match with the global dict --> generate_full_uci_move_vocabulary()\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        fen: FEN notation of the current position\n",
    "    Returns\n",
    "    -------\n",
    "        uci_to_idx: Dict {uci_move : idx}\n",
    "        idc_to_uci: Dict {idx : uci_move}\n",
    "    \"\"\"\n",
    "\n",
    "    board = chess.Board(fen)\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    \n",
    "    legal_moves_sorted = sorted(legal_moves, key=lambda m: m.uci())\n",
    "\n",
    "    uci_to_idx = {move.uci():  idx for idx, move in enumerate(legal_moves_sorted)}\n",
    "    idx_to_uci = {idx: move.uci() for idx,move in enumerate(legal_moves_sorted)}\n",
    "    return uci_to_idx, idx_to_uci\n",
    "\n",
    " ## POSIBLEMENTE DESCARTADO, MEJORA ALTERNATIVA CON FUNCION  --> get_legal_moves_vocab enfoque \"SPARSE\"\n",
    "# def get_legal_mask(board: chess.Board, uci_to_index: dict) -> torch.Tensor:\n",
    "#     mask = torch.zeros(len(uci_to_index), dtype=torch.float32)\n",
    "#     for move in board.legal_moves:\n",
    "#         uci = move.uci()\n",
    "#         if uci in uci_to_index:\n",
    "#             mask[uci_to_index[uci]] = 1.0\n",
    "#     return mask  # Shape: (n_moves,)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    move_list = sorted(move_set)\n",
    "    uci_to_index = {uci: idx for idx, uci in enumerate(move_list)}\n",
    "    index_to_uci = {idx: uci for uci, idx in uci_to_index.items()}\n",
    "    return uci_to_index, index_to_uci\n",
    "# Globales cargados una vez al inicio\n",
    "\n",
    "def move_to_index(uci_move: str) -> int:\n",
    "    return uci_to_index.get(uci_move, -1)  # -1 si no estÃ¡\n",
    "\n",
    "def index_to_move(idx: int) -> str:\n",
    "    return index_to_uci.get(idx, \"0000\")  # dummy por si acaso\n",
    "\n",
    "class ChessSequenceDataset(torch.utils.data.Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self,*,uci_to_idx=None,df=None,games=None):\n",
    "        \"\"\"\n",
    "        Initializes the ChessSequenceDataset with either a dataframe of game moves or a list of game tensors.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "            uci_to_idx:      dict {uci_move : idx}\n",
    "                             Dictionary mapping UCI (Universal Chess Interface) moves to a numerical value. The dictionary represents all possible move classes.\n",
    "                             \n",
    "            df:    pd.DataFrame\n",
    "                             Pandas dataframe which will have a variety of columns, game_id,pyl,fen,and move_uci are relevant for this constructor.\n",
    "                             \n",
    "            games: list(list(Torch.tensor))\n",
    "                             List of half moves represented as Torch.tensors which are the snapshots of a given FEN(Forsyth-Edwards Notation) nested in other list with full games.\n",
    "                             Specifications:\n",
    "                             n_games: number of games\n",
    "                             n_moves_per_game: moves per game\n",
    "                             dim: dimensions of each move's tensor 8*8*12\n",
    "    \n",
    "                             The total dimension: n_games*n_moves_per_game*dim\n",
    "                    \n",
    "        Notes\n",
    "        -----\n",
    "        Either 'df' or 'games' should be provided to create a dataset instance for training an LSTM model.\n",
    "        \n",
    "        \"\"\"\n",
    "        if games is not None:\n",
    "            self.games = games\n",
    "            self.uci_to_idx = uci_to_idx\n",
    "        elif df is not None and uci_to_idx is not None:\n",
    "            self.games = []\n",
    "            self.uci_to_idx = uci_to_idx\n",
    "            grouped = df.groupby('game_id')\n",
    "    \n",
    "            for game_id, group in grouped:\n",
    "                group_sorted = group.sort_values(by='pyl',ascending=True)#group.sort_values(by='pyl',ascending=True)\n",
    "                sequence = []\n",
    "    \n",
    "                for _,row in group_sorted.iterrows():\n",
    "                    fen = row['fen']\n",
    "                    uci = row['move_uci']\n",
    "    \n",
    "                    move_idx = uci_to_idx.get(uci,-1)\n",
    "                    if move_idx ==-1:\n",
    "                        continue\n",
    "                    try:\n",
    "                        fen_tensor = fen_to_tensor(fen)\n",
    "                    except Exception as e:\n",
    "                        print(f'Error in FEN {fen} --->{e}')\n",
    "                        continue\n",
    "                    sequence.append((fen_tensor,move_idx))\n",
    "                if len(sequence)>0:\n",
    "                    self.games.append(sequence)\n",
    "    @classmethod\n",
    "    def from_multiple_files(cls,file_list,uci_to_idx,stop_idx):\n",
    "        \"\"\"\n",
    "        Initializes the ChessSequenceDataset with a file list of games previously processed, within a range of a given index\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            file_list: list\n",
    "                list of paths of files which contain the processed games\n",
    "            uci_to_idx: dict {uci_move: idx}\n",
    "                Dictionary mapping UCI (Universal Chess Interface) moves to a numerical value. The dictionary represents all possible move classes.\n",
    "            stop_idx: int\n",
    "                Determine if the loading should stop in a certain number of processed dataset tho save resources.\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        all_games = []\n",
    "        for _,file in enumerate(file_list):\n",
    "            if _ > stop_idx:\n",
    "                break\n",
    "            games = torch.load(file)\n",
    "            all_games.extend(games)\n",
    "\n",
    "        return cls(games=all_games,uci_to_idx=uci_to_index)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.games)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.games[idx]\n",
    "        \n",
    "def identity_collate(batch):\n",
    "    return batch[0]  # simplemente devuelve la secuencia tal cual\n",
    "\n",
    "class ChessLSTMPolicyNet(torch.nn.Module):\n",
    "    def __init__(self,input_channels=12,lstm_hidden_size=512,lstm_layers=1,output_dim=4544):\n",
    "        \"\"\"\n",
    "        Initialize the ChessLSTMPolicyNet model, inheriting class methods of module torch.nn.Module\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            input_channels: int(12)\n",
    "                Channels of the possible pieces to play in chess, 6 for white and 6 for black\n",
    "            lstm_hidden_size: int(512)\n",
    "                Quantity of LSTM neurons which will be the model trained on\n",
    "            lstm_layers: int(1)\n",
    "                Quantity of layers LSTM\n",
    "            output_dim: int(4544)\n",
    "                Quantity of possible move classes\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(input_channels,64,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.flattened_size = 128*8*8\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size= self.flattened_size,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc = torch.nn.Linear(lstm_hidden_size,output_dim)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "            B, T, C, H, W = x.shape\n",
    "            x = x.view(B * T, C, H, W)           # (B*T, C, 8, 8)\n",
    "            x = self.conv(x)                     # (B*T, 128, 8, 8)\n",
    "            x = x.view(B, T, -1)                 # (B, T, 8192)\n",
    "\n",
    "            lstm_out, _ = self.lstm(x)           # (B, T, hidden)\n",
    "            logits = self.fc(lstm_out)           # (B, T, output_dim)\n",
    "            return logits\n",
    "def train_lstm(model, dataloader, criterion, optimizer,device, epochs=5,start_epoch=0, checkpoint_path='checkpoint.pth'):\n",
    "    \"\"\"\n",
    "    Function to train the model for a given dataset, saving each epoch result to segregate the traning into smaller blocks of processing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model: ChessLSTMPolicyNet\n",
    "            Architecture of the model that define the flow of how the dataloader will be processed for machine learning.\n",
    "        dataloader: torch.utils.data.DataLoader\n",
    "            Iterator of lenght of n_games/batch_size, normally batch_size will be equal to 1, considering that is needed process just complete sequences of a game \n",
    "        criterion: torch.nn.CrossEntropyLoss()\n",
    "            Loss function to calculate the loss \n",
    "        optimizer: torch.optim.Adam()\n",
    "            Opimizer which will help us to optimze the weights in the neural network based on the results of the loss function\n",
    "        device:\n",
    "            Device to perform the training, usually a GPU\n",
    "        epochs:\n",
    "            Number of epochs to iterate the training\n",
    "        start_epoch:\n",
    "            Index from where will be start the training\n",
    "        checkpoint_path: \n",
    "            File with the saved training epochs \"\"\"\n",
    "\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(start_epoch,start_epoch+epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_moves = 0\n",
    "\n",
    "        for sequence in dataloader:\n",
    "            # batch: list of 1 element (sequence of (fen_tensor, move_idx))\n",
    "            if not all(isinstance(x,tuple) and isinstance(x[0],torch.Tensor) for x in sequence):\n",
    "                print('Invalid sequence detected and omitted...')\n",
    "                continue\n",
    "            try: \n",
    "                \n",
    "                inputs = torch.stack([x[0] for x in sequence])  # (T, C, 8, 8)\n",
    "                targets = torch.tensor([x[1] for x in sequence],dtype=torch.long)  # (T,)\n",
    "\n",
    "            # Reshape to (B, T, C, 8, 8)\n",
    "                inputs = inputs.unsqueeze(0).to(device)\n",
    "                targets = targets.unsqueeze(0).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)  # (B, T, output_dim)\n",
    "\n",
    "            # Aplanar para CrossEntropy\n",
    "                logits = outputs.view(-1, outputs.size(-1))     # (T, output_dim)\n",
    "                target_flat = targets.view(-1)                  # (T,)\n",
    "\n",
    "                loss = criterion(logits, target_flat)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                total_loss += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                total_correct += (preds == target_flat).sum().item()\n",
    "                total_moves += target_flat.size(0)\n",
    "            except Exception as e:\n",
    "                print(f'Something went wrong error {e}, skipping sequence')\n",
    "                continue\n",
    "\n",
    "        acc = total_correct / total_moves\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}, Accuracy = {acc:.4f}\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': total_loss\n",
    "        }, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc91e526-b54d-4b09-8859-55fc4351852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_chunks(df, uci_to_idx,chunk_size=50_000, output_prefix='chunk_sequence'):\n",
    "    game_ids = df['game_id'].unique()\n",
    "    total_games = len(game_ids)\n",
    "    num_chunks = (total_games + chunk_size -1) // chunk_size\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        save_path = Path.cwd().parent /'data'/'torch_datasets'/f'{output_prefix}_{i:04d}.pt'\n",
    "        save_path.parent.mkdir(parents=True,exist_ok=True)\n",
    "        print(f'Veryfing if chunk number: {i:04d} exists...')\n",
    "\n",
    "        if os.path.exists(save_path):\n",
    "            print(f'Chunk {i:04d} exist, skipping...')\n",
    "            continue\n",
    "        else:\n",
    "            start = i*chunk_size\n",
    "            end = min(start + chunk_size,total_games)\n",
    "            chunks_ids = game_ids[start:end]\n",
    "            chunk_df = df.loc[df['game_id'].isin(chunks_ids)]\n",
    "    \n",
    "            print(f'Processing chunk number {i}/{num_chunks} with {len(chunks_ids)} games...')\n",
    "            dataset = ChessSequenceDataset(chunk_df,uci_to_idx)\n",
    "    \n",
    "            torch.save(dataset.games,save_path)\n",
    "            print(f'[ðŸ’¾] Saved: {save_path} with {len(dataset)} valid games')\n",
    "    \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe33e03-94cd-4908-bd87-62f1ad8f2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_datasets = glob.glob(str(Path.cwd().parent / 'data'/'torch_datasets'/'*.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23859697-2b58-4d5c-85f9-7dcfafc3213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_datasets = glob.glob(str(Path.cwd().parent / 'data' / 'processed' /'*.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd0e7911-d3fc-4425-a85b-d4842e582693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_parquet(parquet_datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6162a77-57dc-4464-b2b0-c73875109e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_to_idx,idx_to_uci = generate_full_uci_move_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4f270a4-7388-40ce-a8f6-21edfd93c4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_games = df_sample['game_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29272a3a-e944-4734-8f2e-975f5e436d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_games =np.random.choice(unique_games,size=5000,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bca97734-b0cd-4315-b1df-572219108ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df_sample.loc[df_sample['game_id'].isin(sample_games)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7de3d8bb-5a0e-4a69-9317-cae1d63aca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if uci_to_idx:\n",
    "    dataset = ChessSequenceDataset(uci_to_idx=uci_to_idx,df=df_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b53b69b6-76a3-4f34-9d18-f10e12164501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "362faab8-5582-4055-9794-4b308dfaf719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Box 0.0 Outter Box 1024.0\n",
      "Inner Box 512.0 Outter Box 512.0\n",
      "Inner Box 768.0 Outter Box 256.0\n",
      "Inner Box 896.0 Outter Box 128.0\n",
      "Inner Box 960.0 Outter Box 64.0\n",
      "Inner Box 992.0 Outter Box 32.0\n",
      "Inner Box 1008.0 Outter Box 16.0\n",
      "Inner Box 1016.0 Outter Box 8.0\n",
      "Inner Box 1020.0 Outter Box 4.0\n",
      "Inner Box 1022.0 Outter Box 2.0\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for i in range(0,10):\n",
    "    out_box = 1024*(1/2)**t\n",
    "    inner_box = -(1024*(1/2)**t)+1024\n",
    "    t +=1\n",
    "\n",
    "    print(f'Inner Box {inner_box:<03} Outter Box {out_box:<03}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ea6f1d1-b095-4697-ae63-62bffb2271bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Box 0.0 Outter Box 1024.0\n",
      "Inner Box 1024.0 Outter Box 512.0\n",
      "Inner Box 1536.0 Outter Box 256.0\n",
      "Inner Box 1792.0 Outter Box 128.0\n",
      "Inner Box 1920.0 Outter Box 64.0\n",
      "Inner Box 1984.0 Outter Box 32.0\n",
      "Inner Box 2016.0 Outter Box 16.0\n",
      "Inner Box 2032.0 Outter Box 8.0\n",
      "Inner Box 2040.0 Outter Box 4.0\n",
      "Inner Box 2044.0 Outter Box 2.0\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for i in range(0,10):\n",
    "    out_box = 1024*(1/2)**t\n",
    "    inner_box = 1024 *((1-(1/2)**i)/(1-(1/2)))\n",
    "    t +=1\n",
    "\n",
    "    print(f'Inner Box {inner_box:<03} Outter Box {out_box:<03}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a506378-a86e-4c34-be7e-69bbda8c6515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess_ai_env",
   "language": "python",
   "name": "chess_ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
