{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f738d7b1-089b-4b95-8723-97fbba9e189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "import chess\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be9a2093-8711-4726-8647-995475b26ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_uci_move_vocabulary()-> tuple[dict,dict]:\n",
    "\n",
    "    \"\"\"\n",
    "    Generates a set of all the posible movements in a chess board of 64 squares, \n",
    "    create two dictionaries which will represent the board move in uci format and their respective idx value and viceversa\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        uci_to_idx : dict\n",
    "                     All the possible uci moves in a chess board, uci format as keys and idx as values\n",
    "        idx_to_uci : dict \n",
    "                     All the possible uci moves in a chess board, uci format as keys and idx as values\n",
    "    \n",
    "    \"\"\"\n",
    "    move_set = set()\n",
    "    \n",
    "    for from_sq in chess.SQUARES:\n",
    "        for to_sq in chess.SQUARES:\n",
    "            if from_sq == to_sq:\n",
    "                continue\n",
    "                \n",
    "            from_rank = chess.square_rank(from_sq)\n",
    "            to_rank = chess.square_rank(to_sq)\n",
    "            from_file = chess.square_file(from_sq)\n",
    "            to_file = chess.square_file(to_sq)\n",
    "            rank_diff = abs(from_rank - to_rank)\n",
    "            file_diff = abs(from_file - to_file)\n",
    "\n",
    "            if file_diff==0 and rank_diff >= 1 :\n",
    "                move_set.add(chess.Move(from_sq,to_sq).uci())\n",
    "            if rank_diff ==0 and file_diff >= 1:\n",
    "                move_set.add(chess.Move(from_sq,to_sq).uci())\n",
    "            if rank_diff == file_diff:\n",
    "                move_set.add(chess.Move(from_sq,to_sq).uci())\n",
    "            if (rank_diff == 1 and file_diff == 2) or (rank_diff == 2 and file_diff == 1):\n",
    "                move_set.add(chess.Move(from_sq,to_sq).uci())\n",
    "            if (from_rank == 1 and to_rank == 0) or (from_rank == 6 and to_rank == 7):\n",
    "                    for promo in [chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT]:\n",
    "                        move_set.add(chess.Move(from_sq, to_sq, promotion=promo).uci())\n",
    "            \n",
    "            \n",
    "    move_list = sorted(move_set)\n",
    "    \n",
    "    print(f\"Total of valid movements generated: {len(move_list)}\")\n",
    "    print(f\"Preview: {move_list[:10]}...\")\n",
    "    uci_to_idx = {uci: idx for idx, uci in enumerate(move_list)}\n",
    "    idx_to_uci = {idx: uci for idx, uci in enumerate(move_list)}\n",
    "    \n",
    "    \n",
    "    return uci_to_idx,idx_to_uci\n",
    "\n",
    "    \n",
    "def fen_to_tensor(fen:str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts a FEN position into a torch tensor of shape (18,8,8),\n",
    "    18 channels that will represent the possible states of a chess board of 8x8 positions.\n",
    "    Channel 0-11: Positions for pieces PNBRQK(white pieces) or pnbrqk(black pieces)\n",
    "    Channel 12: White kingside castling\n",
    "    Channel 13: White queenside castling\n",
    "    Channel 14: Black kingside castling\n",
    "    Channel 15: Black queenside castling\n",
    "    Channel 16: En passant target square\n",
    "    Channel 17: Turm (1.0 for white or 0.0 for black)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fen : str\n",
    "          The notation FEN to convert into tensor\n",
    "    Returns\n",
    "    -------\n",
    "    board_tensor : torch.Tensor\n",
    "                   The representation of FEN notation in 12 matrix of 8x8\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    board = chess.Board(fen)\n",
    "    \n",
    "    piece_to_index = {piece:idx for idx,piece in enumerate('PNBRQKpnbrqk')}\n",
    "\n",
    "    #12 pieces + 4 castlings + 1 passant + 1 turn = 18 channels\n",
    "    board_tensor = torch.zeros((18,8,8),dtype=torch.float32)\n",
    "\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            idx = piece_to_index[piece.symbol()]\n",
    "            row = 7 - (square // 8)\n",
    "            col = square %8\n",
    "            board_tensor[idx,row,col] = 1.0\n",
    "\n",
    "    \n",
    "    #Channels 12-15: Is Castling available \n",
    "    board_tensor[12, :, :] = 1.0 if board.has_kingside_castling_rights(chess.WHITE) else 0.0\n",
    "    board_tensor[13, :, :] = 1.0 if board.has_queenside_castling_rights(chess.WHITE) else 0.0\n",
    "    board_tensor[14, :, :] = 1.0 if board.has_kingside_castling_rights(chess.BLACK) else 0.0\n",
    "    board_tensor[15, :, :] = 1.0 if board.has_queenside_castling_rights(chess.BLACK) else 0.0\n",
    "\n",
    "    #Channel 16 en passant available\n",
    "    \n",
    "    if board.ep_square is not None:\n",
    "        ep_row = 7 - (board.ep_square //8)\n",
    "        ep_col = board.ep_square % 8\n",
    "        board_tensor[16,ep_row,ep_col] = 1.0\n",
    "    #Channel 17 Turn \n",
    "    board_tensor[17,:,:] = 1.0 if board.turn == chess.WHITE else 0.0\n",
    "            \n",
    "    return board_tensor\n",
    "\n",
    "\n",
    "def get_legal_moves_vocab(fen:str) -> tuple[dict[str,int],dict[int,str]]:\n",
    "    \"\"\"\n",
    "    Generates a set of legal posible moves for a given position \n",
    "\n",
    "    IMPORTANT ---> All the dict generated are LOCAL and could not match with the global dict --> generate_full_uci_move_vocabulary()\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        fen: FEN notation of the current position\n",
    "    Returns\n",
    "    -------\n",
    "        uci_to_idx: Dict {uci_move : idx}\n",
    "        idc_to_uci: Dict {idx : uci_move}\n",
    "    \"\"\"\n",
    "\n",
    "    board = chess.Board(fen)\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    \n",
    "    legal_moves_sorted = sorted(legal_moves, key=lambda m: m.uci())\n",
    "\n",
    "    uci_to_idx = {move.uci():  idx for idx, move in enumerate(legal_moves_sorted)}\n",
    "    idx_to_uci = {idx: move.uci() for idx,move in enumerate(legal_moves_sorted)}\n",
    "    return uci_to_idx, idx_to_uci\n",
    "\n",
    " ## POSIBLEMENTE DESCARTADO, MEJORA ALTERNATIVA CON FUNCION  --> get_legal_moves_vocab enfoque \"SPARSE\"\n",
    "# def get_legal_mask(board: chess.Board, uci_to_index: dict) -> torch.Tensor:\n",
    "#     mask = torch.zeros(len(uci_to_index), dtype=torch.float32)\n",
    "#     for move in board.legal_moves:\n",
    "#         uci = move.uci()\n",
    "#         if uci in uci_to_index:\n",
    "#             mask[uci_to_index[uci]] = 1.0\n",
    "#     return mask  # Shape: (n_moves,)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # move_list = sorted(move_set)\n",
    "    # uci_to_index = {uci: idx for idx, uci in enumerate(move_list)}\n",
    "    # index_to_uci = {idx: uci for uci, idx in uci_to_index.items()}\n",
    "    # return uci_to_index, index_to_uci\n",
    "# Globales cargados una vez al inicio\n",
    "\n",
    "def move_to_index(uci_move: str) -> int:\n",
    "    return uci_to_index.get(uci_move, -1)  # -1 si no estÃ¡\n",
    "\n",
    "def index_to_move(idx: int) -> str:\n",
    "    return index_to_uci.get(idx, \"0000\")  # dummy por si acaso\n",
    "\n",
    "class ChessSequenceDataset(torch.utils.data.Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self,*,uci_to_idx=None,df=None,games=None):\n",
    "        \"\"\"\n",
    "        Initializes the ChessSequenceDataset with either a dataframe of game moves or a list of game tensors.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "            uci_to_idx:      dict {uci_move : idx}\n",
    "                             Dictionary mapping UCI (Universal Chess Interface) moves to a numerical value. The dictionary represents all possible move classes.\n",
    "                             \n",
    "            df:    pd.DataFrame\n",
    "                             Pandas dataframe which will have a variety of columns, game_id,pyl,fen,and move_uci are relevant for this constructor.\n",
    "                             \n",
    "            games: list(list(Torch.tensor))\n",
    "                             List of half moves represented as Torch.tensors which are the snapshots of a given FEN(Forsyth-Edwards Notation) nested in other list with full games.\n",
    "                             Specifications:\n",
    "                             n_games: number of games\n",
    "                             n_moves_per_game: moves per game\n",
    "                             dim: dimensions of each move's tensor 8*8*12\n",
    "    \n",
    "                             The total dimension: n_games*n_moves_per_game*dim\n",
    "                    \n",
    "        Notes\n",
    "        -----\n",
    "        Either 'df' or 'games' should be provided to create a dataset instance for training an LSTM model.\n",
    "        \n",
    "        \"\"\"\n",
    "        if games is not None:\n",
    "            self.games = games\n",
    "            self.uci_to_idx = uci_to_idx\n",
    "        elif df is not None and uci_to_idx is not None:\n",
    "            self.games = []\n",
    "            self.uci_to_idx = uci_to_idx\n",
    "            grouped = df.groupby('game_id')\n",
    "    \n",
    "            for game_id, group in grouped:\n",
    "                group_sorted = group.sort_values(by='ply',ascending=True)\n",
    "                sequence = []\n",
    "    \n",
    "                for _,row in group_sorted.iterrows():\n",
    "                    fen = row['fen']\n",
    "                    uci = row['move_uci']\n",
    "    \n",
    "                    move_idx = uci_to_idx.get(uci,-1)\n",
    "                    if move_idx ==-1:\n",
    "                        continue\n",
    "                    try:\n",
    "                        fen_tensor = fen_to_tensor(fen)\n",
    "                    except Exception as e:\n",
    "                        print(f'Error in FEN {fen} --->{e}')\n",
    "                        continue\n",
    "                    sequence.append((fen_tensor,move_idx,fen))\n",
    "                if len(sequence)>0:\n",
    "                    self.games.append(sequence)\n",
    "    @classmethod\n",
    "    def from_multiple_files(cls,file_list,uci_to_idx,stop_idx):\n",
    "        \"\"\"\n",
    "        Initializes the ChessSequenceDataset with a file list of games previously processed, within a range of a given index\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            file_list: list\n",
    "                list of paths of files which contain the processed games\n",
    "            uci_to_idx: dict {uci_move: idx}\n",
    "                Dictionary mapping UCI (Universal Chess Interface) moves to a numerical value. The dictionary represents all possible move classes.\n",
    "            stop_idx: int\n",
    "                Determine if the loading should stop in a certain number of processed dataset tho save resources.\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        all_games = []\n",
    "        for _,file in enumerate(file_list):\n",
    "            if _ > stop_idx:\n",
    "                break\n",
    "            games = torch.load(file)\n",
    "            all_games.extend(games)\n",
    "\n",
    "        return cls(games=all_games,uci_to_idx=uci_to_index)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.games)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.games[idx]\n",
    "        \n",
    "def identity_collate(batch):\n",
    "    return batch[0]  # simplemente devuelve la secuencia tal cual\n",
    "\n",
    "class ChessLSTMPolicyNet(torch.nn.Module):\n",
    "    def __init__(self,input_channels=18,lstm_hidden_size=128,lstm_layers=1,output_dim=2304):\n",
    "        \"\"\"\n",
    "        Initialize the ChessLSTMPolicyNet model, inheriting class methods of module torch.nn.Module\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            input_channels: int(18)\n",
    "                Channels that will represent the possible states of a chess board of 8x8 positions. fen_to_tensor()\n",
    "            lstm_hidden_size: int(512)\n",
    "                Quantity of LSTM neurons which will be the model trained on\n",
    "            lstm_layers: int(1)\n",
    "                Quantity of layers LSTM\n",
    "            output_dim: int(4544)\n",
    "                Quantity of possible move classes\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(input_channels,64,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.flattened_size = 128*8*8\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size= self.flattened_size,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc = torch.nn.Linear(lstm_hidden_size,output_dim)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "            B, T, C, H, W = x.shape\n",
    "            x = x.view(B * T, C, H, W)           # (B*T, C, 8, 8)\n",
    "            x = self.conv(x)                     # (B*T, 128, 8, 8)\n",
    "            x = x.view(B, T, -1)                 # (B, T, 8192)\n",
    "\n",
    "            lstm_out, _ = self.lstm(x)           # (B, T, hidden)\n",
    "            logits = self.fc(lstm_out)           # (B, T, output_dim)\n",
    "            return logits\n",
    "\n",
    "        \n",
    "def train_lstm(model,uci_to_idx_global, train_dataloader,val_dataloader, criterion, optimizer,device, epochs=5,start_epoch=0, checkpoint_path='checkpoint.pth'):\n",
    "    \"\"\"\n",
    "    Function to train the model for a given dataset, saving each epoch result to segregate the traning into smaller blocks of processing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model: ChessLSTMPolicyNet\n",
    "            Architecture of the model that define the flow of how the dataloader will be processed for machine learning.\n",
    "        dataloader: torch.utils.data.DataLoader\n",
    "            Iterator of lenght of n_games/batch_size, normally batch_size will be equal to 1, considering that is needed process just complete sequences of a game \n",
    "        criterion: torch.nn.CrossEntropyLoss()\n",
    "            Loss function to calculate the loss \n",
    "        optimizer: torch.optim.Adam()\n",
    "            Opimizer which will help us to optimze the weights in the neural network based on the results of the loss function\n",
    "        device:\n",
    "            Device to perform the training, usually a GPU\n",
    "        epochs:\n",
    "            Number of epochs to iterate the training\n",
    "        start_epoch:\n",
    "            Index from where will be start the training\n",
    "        checkpoint_path: \n",
    "            File with the saved training epochs \"\"\"\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'train_acc':[],\n",
    "        'train_loss':[],\n",
    "        'val_acc':[],\n",
    "        'val_loss':[],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(start_epoch,start_epoch+epochs):\n",
    "        total_train_loss = 0\n",
    "        total_train_correct = 0\n",
    "        total_train_moves = 0\n",
    "        model.train()\n",
    "\n",
    "        for game in train_dataloader:\n",
    "            # batch: list of 1 element (game of (fen_tensor, move_idx))\n",
    "            if not all(isinstance(x,tuple) and isinstance(x[0],torch.Tensor) for x in game):\n",
    "                print('Invalid game detected and omitted in train train_dataloader...')\n",
    "                continue\n",
    "            try: \n",
    "                # Dataset attributes\n",
    "                inputs = torch.stack([x[0] for x in game])  # Representation of FEN in torch tensor (T, C, 8, 8)\n",
    "                targets = torch.tensor([x[1] for x in game],dtype=torch.long)  # (T,)\n",
    "                fens = [x[2] for x in game]\n",
    "                \n",
    "            # Reshape to (B, T, C, 8, 8)\n",
    "                inputs = inputs.unsqueeze(0).to(device)\n",
    "                targets = targets.unsqueeze(0).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)  # (B, T, output_dim)\n",
    "\n",
    "            # Aplanar para CrossEntropy\n",
    "                logits = outputs.view(-1, outputs.size(-1))     # (Channels = 18, 8, 8)\n",
    "                masked_logits = mask_logits(uci_to_idx_global,fens,logits)\n",
    "                target_flat = targets.view(-1)                  # (T,)\n",
    "\n",
    "                loss = criterion(masked_logits, target_flat)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                total_train_loss += loss.item()\n",
    "                preds =  torch.argmax(masked_logits, dim=1)#torch.argmax(logits, dim=1)\n",
    "                total_train_correct += (preds == target_flat).sum().item()\n",
    "                total_train_moves += target_flat.size(0)\n",
    "            except Exception as e:\n",
    "                print(f'Something went wrong: {type(e).__name__}: {e}')\n",
    "                continue\n",
    "        train_acc = total_train_correct / total_train_moves\n",
    "        train_loss = total_train_loss/len(train_dataloader)\n",
    "\n",
    "    ##add validation\n",
    "        model.eval()\n",
    "    \n",
    "        total_val_loss = 0\n",
    "        total_val_correct = 0\n",
    "        total_val_moves = 0\n",
    "        with torch.no_grad():\n",
    "            for game in val_dataloader:\n",
    "                if not all(isinstance(x,tuple) and isinstance(x[0],torch.Tensor) for x in game):\n",
    "                    print('Invalid game detected and omitted in val_dataloader...')\n",
    "                    continue\n",
    "                try: \n",
    "                        \n",
    "                    inputs = torch.stack([x[0] for x in game])  # (Channels = 18, 8, 8)\n",
    "                    targets = torch.tensor([x[1] for x in game],dtype=torch.long)  # idx_move \n",
    "                    fens = [x[2] for x in game]\n",
    "        \n",
    "                    # Reshape to (B, T, C, 8, 8)\n",
    "                    inputs = inputs.unsqueeze(0).to(device)\n",
    "                    targets = targets.unsqueeze(0).to(device)\n",
    "                        \n",
    "                    outputs = model(inputs)  # (B, T, output_dim)\n",
    "        \n",
    "                     \n",
    "        \n",
    "                    # Aplanar para CrossEntropy\n",
    "                    logits = outputs.view(-1, outputs.size(-1))     # (T, output_dim)\n",
    "                    masked_logits=mask_logits(uci_to_idx_global,fens,logits)\n",
    "                    target_flat = targets.view(-1)                  # (T,)\n",
    "                    loss = criterion(masked_logits,target_flat)\n",
    "                    total_val_loss += loss.item()\n",
    "                    preds = torch.argmax(masked_logits, dim=1)\n",
    "                    total_val_correct += (preds == target_flat).sum().item()\n",
    "                    total_val_moves += target_flat.size(0)\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    print(f'Something went wrong during validation: {type(e).__name__}: {e}')\n",
    "                \n",
    "            val_acc = total_val_correct/total_val_moves\n",
    "            val_loss = total_val_loss/len(val_dataloader)\n",
    "\n",
    "        # --- LOGGING ---\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")  # CORRECCIÃN: Mensaje completo\n",
    "        history['epoch'].append(epoch + 1)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        # Save checkpoint with both train and validation metrics\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_acc': val_acc\n",
    "        }, checkpoint_path)\n",
    "    return history\n",
    "            \n",
    "\n",
    "        \n",
    "def mask_logits(uci_to_idx_global, fens, logits):\n",
    "    masked_logits = []\n",
    "    missing_moves = set()\n",
    "    \n",
    "    for t, fen_str in enumerate(fens):\n",
    "        board = chess.Board(fen_str)\n",
    "        mask = torch.full((logits.size(1),), float('-inf'), device=logits.device)\n",
    "        \n",
    "        for move in board.legal_moves:\n",
    "            uci = move.uci()\n",
    "            if uci in uci_to_idx_global:\n",
    "                mask[uci_to_idx_global[uci]] = 0\n",
    "            else:\n",
    "                missing_moves.add(uci)  # Para debugging\n",
    "        \n",
    "        if missing_moves:\n",
    "            print(f\"â ï¸ Movimientos faltantes en el vocabulario: {missing_moves}\")\n",
    "            \n",
    "        masked_logits.append(logits[t] + mask)\n",
    "    \n",
    "    return torch.stack(masked_logits, dim=0)       \n",
    "\n",
    "# def mask_logits(uci_to_idx_global,fens,logits):\n",
    "#     masked_logits = []\n",
    "#     for t, fen_str in enumerate(fens):\n",
    "#         board = chess.Board(fen_str)\n",
    "#         legal_idxs = [uci_to_idx_global[m.uci()] for m in board.legal_moves if m.uci() in uci_to_idx_global]\n",
    "#         mask = torch.full((logits.size(1),),fill_value=float('-inf'),device=logits.device)\n",
    "#         mask[legal_idxs] = 0\n",
    "#         masked_logits.append(logits[t] + mask)\n",
    "#     masked_logits = torch.stack(masked_logits,dim=0)\n",
    "#     return masked_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f49dafe-a3ae-4090-9ba4-38b7b64f2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_chunks(df, uci_to_idx,chunk_size=50_000, output_prefix='chunk_sequence'):\n",
    "    game_ids = df['game_id'].unique()\n",
    "    total_games = len(game_ids)\n",
    "    num_chunks = (total_games + chunk_size -1) // chunk_size\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        save_path = Path.cwd().parent /'data'/'torch_datasets'/f'{output_prefix}_{i:04d}.pt'\n",
    "        save_path.parent.mkdir(parents=True,exist_ok=True)\n",
    "        print(f'Veryfing if chunk number: {i:04d} exists...')\n",
    "\n",
    "        if os.path.exists(save_path):\n",
    "            print(f'Chunk {i:04d} exist, skipping...')\n",
    "            continue\n",
    "        else:\n",
    "            start = i*chunk_size\n",
    "            end = min(start + chunk_size,total_games)\n",
    "            chunks_ids = game_ids[start:end]\n",
    "            chunk_df = df.loc[df['game_id'].isin(chunks_ids)]\n",
    "    \n",
    "            print(f'Processing chunk number {i}/{num_chunks} with {len(chunks_ids)} games...')\n",
    "            dataset = ChessSequenceDataset(chunk_df,uci_to_idx)\n",
    "    \n",
    "            torch.save(dataset.games,save_path)\n",
    "            print(f'[ð¾] Saved: {save_path} with {len(dataset)} valid games')\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "# torch_datasets = glob.glob(str(Path.cwd().parent / 'data'/'torch_datasets'/'*.pt'))\n",
    "\n",
    "# parquet_datasets = glob.glob(str(Path.cwd().parent / 'data' / 'processed' /'*.parquet'))\n",
    "\n",
    "# df_sample = pd.read_parquet(parquet_datasets[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da3d4c4a-a488-4a04-9ae9-a224ebfb365d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_id\n",
       "97062     296\n",
       "56405     285\n",
       "139992    281\n",
       "133232    268\n",
       "26037     257\n",
       "         ... \n",
       "8217        1\n",
       "14990       1\n",
       "27958       1\n",
       "123309      1\n",
       "6412        1\n",
       "Name: count, Length: 150016, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moves_count = df_sample['game_id'].value_counts()\n",
    "# moves_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "375ad708-b3ea-42d5-85bd-963d07e26c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150016"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c730008f-8ebd-4a86-afc4-999a40e228cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "\n",
    "# moves_count = df_sample['game_id'].value_counts()\n",
    "\n",
    "# fig = go.Figure(data=[\n",
    "#     go.Histogram(\n",
    "#         x=moves_count.values,\n",
    "#         nbinsx=50  # puedes ajustar el nÃºmero de bins (ej. 50, 100, etc.)\n",
    "#     )\n",
    "# ])\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=\"DistribuciÃ³n de jugadas por partida\",\n",
    "#     xaxis_title=\"NÃºmero de jugadas\",\n",
    "#     yaxis_title=\"NÃºmero de partidas\",\n",
    "#     bargap=0.05\n",
    "# )\n",
    "\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72ccf4b0-b828-4d12-8e59-3de538819c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of valid movements generated: 2304\n",
      "Preview: ['a1a2', 'a1a3', 'a1a4', 'a1a5', 'a1a6', 'a1a7', 'a1a8', 'a1b1', 'a1b2', 'a1b3']...\n"
     ]
    }
   ],
   "source": [
    "# uci_to_idx,idx_to_uci = generate_full_uci_move_vocabulary()\n",
    "\n",
    "# unique_games = df_sample['game_id'].unique()\n",
    "\n",
    "# sample_games =np.random.choice(unique_games,size=15*10**3,replace=False)\n",
    "\n",
    "\n",
    "# X_train,X_val= train_test_split(sample_games,test_size=.2,random_state=42)\n",
    "# df_sample_train = df_sample.loc[df_sample['game_id'].isin(X_train)].copy()\n",
    "# df_sample_val = df_sample.loc[df_sample['game_id'].isin(X_val)].copy()\n",
    "\n",
    "# if uci_to_idx:\n",
    "#     train_dataset = ChessSequenceDataset(uci_to_idx=uci_to_idx,df=df_sample_train)\n",
    "#     val_dataset = ChessSequenceDataset(uci_to_idx=uci_to_idx,df=df_sample_val)\n",
    "\n",
    "    \n",
    "\n",
    "# train_dataloader =torch.utils.data.DataLoader(train_dataset,batch_size=1,collate_fn=identity_collate)\n",
    "# val_dataloader =torch.utils.data.DataLoader(val_dataset,batch_size=1,collate_fn=identity_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636678e8-23aa-4a17-a2b2-7bfde5c356d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 2.6524, Train Acc = 0.2319, Val Loss = 2.4482, Val Acc = 0.2786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = ChessLSTMPolicyNet().to(device)\n",
    "\n",
    "# history = train_lstm(\n",
    "#     model=model,\n",
    "#     uci_to_idx_global = uci_to_idx,\n",
    "#     train_dataloader=train_dataloader,\n",
    "#     val_dataloader= val_dataloader,\n",
    "#     criterion=torch.nn.CrossEntropyLoss(),\n",
    "#     optimizer=torch.optim.Adam(model.parameters(),lr=1e-3),\n",
    "#     device=device\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1a1d8-13e2-4651-813f-2d90f352f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "0/0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
